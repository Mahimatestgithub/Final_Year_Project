# AI-Powered Intelligent In-Car Assistant 🚘🧠🌿

This project is a **Final Year Engineering Project** that integrates cutting-edge AI technologies to build an **intelligent in-car assistant**. The assistant enhances driver well-being, improves road safety, and helps protect wildlife — offering a holistic solution for modern, smart driving.

---

## 🔍 Project Overview

The system combines three powerful modules:
- 🎵 Emotion-Responsive Music Therapy
- 😡 Road Rage Detection & Intervention
- 🦌 Wildlife Detection & Roadkill Prevention

It uses a combination of **computer vision**, **natural language processing**, **voice emotion detection**, and **IoT integration** to improve driving experience and safety.

---

## 📦 Core Modules

### 1. Emotion-Responsive Music Therapy
- Uses a camera to detect driver facial expressions using CNN-based deep learning models.
- Optional: Sentiment analysis from user text input via HuggingFace Transformers.
- Integrates with **Spotify API** to recommend playlists based on emotional state.
- Real-time mood tracking dynamically updates music to suit the driver’s emotions.

### 2. Road Rage Detection & Intervention
- Detects anger or stress using facial expression and voice tone analysis (via Google Speech-to-Text).
- Initiates **calming interventions** such as:
  - Playing relaxing music
  - Guiding breathing exercises on the screen
- Logs incidents for analyzing long-term behavioral trends.

### 3. Wildlife Detection & Roadkill Prevention
- Uses **FLIR infrared cameras** and YOLOv8 to detect animals on roads, even at night.
- Alerts drivers immediately and also:
  - Displays warnings on smart traffic signs
  - Activates IoT-based dynamic speed boards
- Provides a wildlife analytics dashboard for authorities.

---

## 🛠 Technologies Used

| Component           | Technology                         |
|---------------------|-------------------------------------|
| Emotion Detection   | OpenCV, CNN, TensorFlow/Keras       |
| Voice Analysis      | Google Speech-to-Text, NLP          |
| Object Detection    | YOLOv8, FLIR Infrared Imaging       |
| Sentiment Analysis  | HuggingFace Transformers            |
| Music Recommendation| Spotify API                         |
| IoT Communication   | MQTT Protocol                       |
| Dashboards          | Streamlit, Dash                     |

---

## 🚦 Roadmap

### ✅ Phase 1: Research & Data Collection
- Facial emotion datasets, voice samples, animal crossing data

### ✅ Phase 2: Model Training
- CNN for facial expressions, YOLOv8 for animal detection, speech analysis

### ✅ Phase 3: API & System Integration
- Spotify API, Google APIs, IoT for alerts

### 🔄 Phase 4-6: Prototyping, Field Testing, and Deployment

---

## 💡 Use Cases

- **Stress-Free Driving** through responsive music
- **Accident Prevention** by managing road rage behavior
- **Wildlife Protection** and reduced vehicle-animal collisions
- **Smart City Integration** via connected alerts and real-time analytics

---

## 🙌 Contributors

- 👩‍💻 **Mahima Gupta** – Project Lead & Developer  
- 🧑‍💻 **Divyanshu Kumar** – Core ML Developer & Systems Integrator
- 👩‍💻 **Shruti Rani** – Team Member  
- 👩‍💻 **Darakhshan Naheed** – Team Member  
- 🧑‍💻 **Vimlendra Mishra** – Team Member  
- 📍 Supported by: Dumka Engineering College (Final Year Project)

---

## 📄 License

This project is open-sourced for educational and research purposes. Contributions and forks are welcome!

---

## 📷 Screenshots & Demo (Coming Soon!)

Stay tuned for the UI previews, real-time demo videos, and dashboard analytics.

---

